{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image center 50*50 piexls data extraction\n",
    "def ave_rgb(img):\n",
    "    x,y,_ = img.shape\n",
    "    temp = []\n",
    "    for i in range(x//2-25,x//2+25):\n",
    "        for j in range(y//2-25,y//2+25):\n",
    "            rgb = img[i,j]\n",
    "            temp.append(rgb.tolist())\n",
    "    df_temp = pd.DataFrame(temp)\n",
    "    return df_temp.mean().values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculat the average RGB values of 50*50 pixels and store in the data list files\n",
    "# Data list is the excel file that store all the image information, including image number, concentration, features\n",
    "import math\n",
    "\n",
    "temp = os.listdir(\"./working folder\")\n",
    "dir = './working folder'\n",
    "name_list = []\n",
    "for ele in temp:\n",
    "    if ('JPG' in ele) or ('jpg' in ele) :\n",
    "        name_list.append(ele)\n",
    "df = pd.read_excel('./working folder/data list.xlsx')\n",
    "reshap_res = []\n",
    "for name in name_list:\n",
    "    img = cv2.imread(os.path.join(dir,name))\n",
    "    r,g,b = ave_rgb(img)\n",
    "    num = int(name.split('.')[0])\n",
    "    row = df[df['No']==num].values.tolist()[0]\n",
    "    reshap_res.append(row+[math.trunc(r),math.trunc(g),math.trunc(b)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsn = pd.DataFrame(reshap_res,columns = ['Label','Con','Abs','No','container','light','phone','R','G','B'])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "inputs = dfsn[['vessel','light','phone','R','G','B','Con']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming dfsn is your DataFrame\n",
    "inputs = dfsn.loc[(((dfsn['No'] < 1922) & (dfsn['No'] > 0))),:][['container', 'light', 'Label', 'phone', 'R', 'G', 'B', 'Con']]\n",
    "\n",
    "\n",
    "# Lists to store RMSE, R2, and feature importances for each split\n",
    "rmses = []\n",
    "r2s = []\n",
    "feature_importances = []\n",
    "\n",
    "# Loop over different random states for train-test split\n",
    "for random_state in range(42, 62):\n",
    "    train, test = train_test_split(inputs, test_size=0.2, stratify=inputs['Label'], random_state=random_state)\n",
    "\n",
    "    train_y = train['Con']\n",
    "    train_x = train.drop(['Label', 'Con'], axis=1)\n",
    "\n",
    "    test_y = test['Con']\n",
    "    test_x = test.drop(['Label', 'Con'], axis=1)\n",
    "\n",
    "    # Train the model\n",
    "    model = RandomForestRegressor(n_estimators=1000, n_jobs=-1, random_state=random_state)\n",
    "    model.fit(train_x, train_y)\n",
    "\n",
    "    # Store the feature importances\n",
    "    feature_importances.append(model.feature_importances_)\n",
    "\n",
    "    # Make predictions\n",
    "    pre_test_y = model.predict(test_x)\n",
    "\n",
    "    # Calculate and store RMSE and R2\n",
    "    rmse = np.sqrt(mean_squared_error(test_y, pre_test_y))\n",
    "    r2 = r2_score(test_y, pre_test_y)\n",
    "    rmses.append(rmse)\n",
    "    r2s.append(r2)\n",
    "\n",
    "# Calculate average and standard deviation of RMSE, R2, and feature importances\n",
    "average_rmse = np.mean(rmses)\n",
    "std_rmse = np.std(rmses)\n",
    "average_r2 = np.mean(r2s)\n",
    "std_r2 = np.std(r2s)\n",
    "\n",
    "# Convert list of feature importances to DataFrame and calculate mean and std\n",
    "feature_importances_df = pd.DataFrame(feature_importances, columns=train_x.columns)\n",
    "average_feature_importances = feature_importances_df.mean()\n",
    "std_feature_importances = feature_importances_df.std()\n",
    "\n",
    "print(f\"Average RMSE: {average_rmse}, Standard Deviation of RMSE: {std_rmse}\")\n",
    "print(f\"Average R2: {average_r2}, Standard Deviation of R2: {std_r2}\")\n",
    "print(\"Average Feature Importances:\")\n",
    "print(average_feature_importances)\n",
    "print(\"\\nStandard Deviation of Feature Importances:\")\n",
    "print(std_feature_importances)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a2deb130ef8b88809166a50c175909f3e1288ebcab452da500041397f4b8aac1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.15 64-bit ('haiping': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
